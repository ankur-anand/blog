<!DOCTYPE html><html class="light page-post"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><title>A visual guide to Go Memory Allocator from scratch (Golang) | Ankur Anand</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><link rel="canonical" href="http://blog.ankuranand.com/2019/02/20/a-visual-guide-to-golang-memory-allocator-from-ground-up/"><meta name="title" content="A visual guide to Go Memory Allocator from scratch (Golang)"><meta name="referrer" content="unsafe-url"><meta name="author" content="Ankur Anand"><meta name="keywords" content="go,golang,memory,internals,"><meta name="description" content="When I first started trying to understand the memory allocator of Go, it was maddening. Everything seemed like a mystical black box. As almost every technical wizardry is hidden beneath abstractions,"><meta name="keywords" content="go,golang,memory,internals"><meta property="og:type" content="article"><meta property="og:title" content="A visual guide to Go Memory Allocator from scratch (Golang)"><meta property="og:url" content="http://blog.ankuranand.com/2019/02/20/a-visual-guide-to-golang-memory-allocator-from-ground-up/"><meta property="og:site_name" content="Ankur Anand"><meta property="og:description" content="When I first started trying to understand the memory allocator of Go, it was maddening. Everything seemed like a mystical black box. As almost every technical wizardry is hidden beneath abstractions,"><meta property="og:locale" content="en"><meta property="og:image" content="https://cdn-images-1.medium.com/max/2000/1*FS11mGLFn7uyeSlJq15K6g.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/2000/1*4Zygvzn9hwFc3NCg8uWUYQ.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/2000/1*ry7d7jMPW5_GzyPPmHubgA.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/3682/1*ImbY2Tb3wZaeuKblwarFTg.jpeg"><meta property="og:image" content="https://cdn-images-1.medium.com/max/2000/1*xek5BQhJhWqsOPAaA5uROw.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/3228/1*Un3ffseQYt_y3vzObgMqfg.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/2000/1*mvi6PRy9wu0KmBcP9YT5Cw.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/2000/1*xeMzyUdfZe9HBQABl2t9Og.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/2728/1*L6MpddL2RZY-kmguKL29jw.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/3558/1*WBLW_v9sLqFMwNdn_DZ9AA.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/2000/1*dWZLGb3sJWncTdEFVuhxzw.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/2540/1*wF9KuVSk8o-16N64kB11UA.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/3086/1*EU3BwOrCI7KIFEninr-bxA.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/3714/1*5eLTsavMYrixqr4H99FwmA.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/3762/1*_j2eG0lUdVQ8NRwgYy-DyA.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/2786/1*rTsieglF6GO1NW78KN8vkQ.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/2000/1*4bePvN9LhkTkPWlRIWGgew.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/3458/1*JBeUo5u5l45-3qzEQrpJ3A.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/3148/1*yX9Q92T4B1aHEoQWTQI36g.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/3294/1*5pyhqsz3aVLyY_kRFc7Lig.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/3760/1*T9WO7O3EWTWJjCrxaOz4cg.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/10000/1*-OQBs5b4u65NRQM8aFukAw.png"><meta property="og:updated_time" content="2019-06-09T16:07:25.432Z"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="A visual guide to Go Memory Allocator from scratch (Golang)"><meta name="twitter:description" content="When I first started trying to understand the memory allocator of Go, it was maddening. Everything seemed like a mystical black box. As almost every technical wizardry is hidden beneath abstractions,"><meta name="twitter:image" content="https://cdn-images-1.medium.com/max/2000/1*FS11mGLFn7uyeSlJq15K6g.png"><meta name="twitter:creator" content="@in_aanand"><meta property="article:author" content="https://ankuranand.com/"><meta name="robots" content="index, follow"><link rel="icon" href="/images/favicon.png"><link href="/css/styles.css?v=c114cbeddx" rel="stylesheet"><link rel="stylesheet" href="/css/personal-style.css"></head></html><body><span id="toolbox-mobile" class="toolbox-mobile">Blog</span><div class="post-header CENTER"><div class="toolbox"><a class="toolbox-entry" href="/"><span class="toolbox-entry-text">Blog</span> <i class="icon-angle-down"></i> <i class="icon-home"></i></a><ul class="list-toolbox"><li class="item-toolbox"><a class="CIRCLE" href="https://ankuranand.com" rel="noopener noreferrer" target="_self">About</a></li><li class="item-toolbox"><a class="CIRCLE" href="/atom.xml" rel="noopener noreferrer" target="_blank">RSS</a></li><li class="item-toolbox"><a class="CIRCLE" href="/search/" rel="noopener noreferrer" target="_self">Search</a></li></ul></div></div><div class="content content-post CENTER"><article id="post-a-visual-guide-to-golang-memory-allocator-from-ground-up" class="article article-type-post" itemprop="blogPost"><header class="article-header"><h1 class="post-title">A visual guide to Go Memory Allocator from scratch (Golang)</h1><div class="article-meta"><span><i class="icon-calendar"></i> <span>2019.02.20</span> </span><span class="article-author"><i class="icon-user"></i> <span>Ankur Anand</span> </span><span class="article-category"><i class="icon-list"></i> <a class="article-category-link" href="/categories/golang/">golang</a></span></div></header><div class="article-content"><p>When I first started trying to understand the memory allocator of Go, it was maddening. Everything seemed like a mystical black box. As almost every technical wizardry is hidden beneath abstractions, you need to peel off those layers one by one to understand it.</p><p>In this blog post, we will exactly do that. Do you want to learn everything about Go memory allocator? You’re reading the right article.</p><p>Translated by readers into: <a href="https://habr.com/ru/company/ruvds/blog/442648/" target="_blank" rel="noopener">Russian</a>, <a href="https://www.linuxzen.com/go-memory-allocator-visual-guide.html" target="_blank" rel="noopener">Chinese</a>.</p><h2 id="Physical-and-Virtual-Memory"><a href="#Physical-and-Virtual-Memory" class="headerlink" title="Physical and Virtual Memory"></a>Physical and Virtual Memory</h2><p>Every Memory Allocator needs to work with the Virtual Memory Space that is managed by the underlying Operating System. Let’s see how it works.</p><p><em>A simple illustration of a Physical Memory Cell (Not an exact representation)</em><br><img src="https://cdn-images-1.medium.com/max/2000/1*FS11mGLFn7uyeSlJq15K6g.png" alt="A simple illustration of a Physical Memory Cell (Not an exact representation)"></p><p><strong>A greatly simplified overview of a single memory cell:</strong></p><p><strong>1.</strong> Address line (transistor as a switch) is what provides access to the capacitor (Data to Data lines).</p><p><strong>2.</strong> When the Address line has current flowing (shown as red), the data line may write to the capacitor, so the capacitor is charged, and the logical value stored is “1”.</p><p><strong>3.</strong> When the Address line has no current flowing (shown as green), the data line may not write to the capacitor, so the capacitor is uncharged, and the logical value stored is “0”.</p><p><strong>4.</strong> When the CPU needs to “READ” a value from RAM, an electric current is sent along the “ADDRESS LINE” (closing the switch). If the capacitor is holding a charge, the current flows down the “DATA LINE” (value of 1); otherwise no current flows down the DATA LINE, so the capacitor stays uncharged (value of 0).</p><p><em>Simple Illustration of how a Physical Memory Cell interacts with CPU</em><br><img src="https://cdn-images-1.medium.com/max/2000/1*4Zygvzn9hwFc3NCg8uWUYQ.png" alt="Simple Illustration of how a Physical Memory Cell interacts with CPU"></p><p><strong>Data Bus:</strong> Transports data between CPU and Physical Memory.</p><p>Let’s also talk a little bit about <strong>Address line</strong> and <strong>Addressable bytes.</strong></p><p><em>Illustrative Representation of an Address Line between CPU and Physical Memory.</em><br><img src="https://cdn-images-1.medium.com/max/2000/1*ry7d7jMPW5_GzyPPmHubgA.png" alt="Illustrative Representation of an Address Line between CPU and Physical Memory."></p><p><strong>1.</strong> Each “BYTE” in DRAM is assigned a unique numeric identifier (address).<br><strong>“Physical bytes present != Number of address line”.</strong> (<em>e.g. 16bit intel 8088, PAE</em>)</p><p><strong>2.</strong> Each “Address line can send 1-bit value, so it specifies a “SINGLE<br>BIT” in the address of a given byte.</p><p><strong>3.</strong> In our Diagram, we have a <strong>32 </strong>address line. So each addressable <strong>BYTE</strong> gets “32 bit” as an address.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ 00000000000000000000000000000000 ] — low memory address.</span><br><span class="line">[ 11111111111111111111111111111111 ] — high memory address.</span><br></pre></td></tr></table></figure><p><strong>4.</strong> Since we have a 32-bit address for each byte, so our address space consists of ²³² addressable bytes (4 GB) (in the above Illustrative representation).</p><p>So the addressable bytes depends upon the total address line, so for 64 address line (x86–64 CPUs) ²⁶⁴ bytes of addressable bytes (16 exabytes), but most architectures that use 64-bit pointers actually use 48-bit address lines (AMD64) and 42-bit address lines (Intel) theoretically allowing 256 terabytes of physical RAM ( Linux allows 128TB of address space per process on x86–64 <a href="https://www.kernel.org/doc/Documentation/x86/x86_64/mm.txt" target="_blank" rel="noopener">with 4 level page tables</a>, windows 192TB)</p><p>As the size of physical RAM is limited, so Each Process runs in its own memory sandbox — “virtual address space,” known as <strong>Virtual Memory.</strong></p><p><strong>Address of a byte in this virtual address space is no longer the same as the address that the processor places on the address bus</strong>. So, the translation data structures and a system have to be established to map a byte in the virtual address space to a physical byte.</p><p>How does this virtual address look like?</p><p><em>Virtual Address Space Representation</em><br><img src="https://cdn-images-1.medium.com/max/3682/1*ImbY2Tb3wZaeuKblwarFTg.jpeg" alt="Virtual Address Space Representation"></p><p>So when the CPU executes an instruction that refers to a memory address. The first step is translating that logic address in the VMA into a <strong>linear address. </strong>This translation is done by <strong>MMU</strong>.</p><p><em>This is <strong>not</strong> a physical diagram, only a depiction. address translation process not included for simplicity</em><br><img src="https://cdn-images-1.medium.com/max/2000/1*xek5BQhJhWqsOPAaA5uROw.png" alt="This is **not** a physical diagram, only a depiction. address translation process not included for simplicity"></p><p>Since this logical address is too large to be practically (depends upon various factor) managed individually, these are managed in term of <strong>pages. </strong>When the necessary paging constructs have been activated, the <strong>virtual memory space is divided into smaller regions called pages (</strong>4kB on most OS<strong> </strong>can be changed<strong>). </strong>It is the smallest unit of data for memory management in virtual memory. Virtual memory doesn’t store anything, it simply <em>maps</em> a program’s address space onto the underlying physical memory.</p><p>Individual Process only sees this VMA as their Address. <strong>So what happens when our program request for more “heap memory”.</strong></p><p><em>A simple assembly code asking for more heap memory.</em><br><img src="https://cdn-images-1.medium.com/max/3228/1*Un3ffseQYt_y3vzObgMqfg.png" alt="A simple assembly code asking for more heap memory."></p><p><em>heap memory increment</em><br><img src="https://cdn-images-1.medium.com/max/2000/1*mvi6PRy9wu0KmBcP9YT5Cw.png" alt="heap memory increment"></p><p>Program asks for more memory. via the <a href="http://www.kernel.org/doc/man-pages/online/pages/man2/brk.2.html" target="_blank" rel="noopener">brk</a> ( sbrk/mmap etc) system call.<br>The kernel updates merely the heap VMA and calls it good.</p><blockquote><p>No page frames are actually allocated at this point and the new pages are not present in physical memory. Point of difference between VSZ vs RSS Size.</p></blockquote><h2 id="Memory-Allocator"><a href="#Memory-Allocator" class="headerlink" title="Memory Allocator"></a>Memory Allocator</h2><p>With the basic overview of “Virtual Address Space”, and what it means to increase the heap, the memory allocator becomes easier to reason now.</p><blockquote><p>If there is enough space in the heap to satisfy a memory request from our code, Memory allocator can fulfill the request without kernel involvement, else it enlarges heap via a system (<em>brk</em>) call, usually requesting a large block of memory. (For malloc large mean &gt; MMAP_THRESHOLD bytes -128 kB by default).</p></blockquote><p>However, memory allocator has more responsibility than merely updating the brk address. One of the major being how to <strong>reduce </strong>both internaland fragmentationexternal<strong> </strong>and how <strong>fast </strong>it can allocate this block<strong>. </strong>Consider the request of a contiguous memory block from our program using a function malloc(size) and releasing that memory back using a function free(pointer) in a sequential way from p1 to p4.</p><p><em>An external fragmentation demonstration</em><br><img src="https://cdn-images-1.medium.com/max/2000/1*xeMzyUdfZe9HBQABl2t9Og.png" alt="An external fragmentation demonstration"></p><p>At p4 step even though we have enough memory block we cannot fulfill the request for 6 contiguous blocks of memory resulting in memory fragmentation.</p><p><strong>So how do we reduce the memory fragment?</strong> The answer to this question depends on the specific memory allocation algorithm, the underlying library use.</p><p>We will be looking into an overview of TCMalloc a memory allocator on which closely the Go memory allocator is modeled.</p><h2 id="TCMalloc"><a href="#TCMalloc" class="headerlink" title="TCMalloc"></a>TCMalloc</h2><p>The core idea of <a href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html" target="_blank" rel="noopener">TCMalloc (thread cache malloc)</a> is to divide the memory into multiple levels to reduce the granularity of the lock. Inside TCMalloc Memory management is divided into two parts: <strong>thread memory</strong> and <strong>page heap</strong>.</p><h3 id="thread-memory"><a href="#thread-memory" class="headerlink" title="thread memory"></a>thread memory</h3><p>Each memory page divided into — Free List of multiple fixed allocatable size-classes, which helps in reducing <strong>fragmentation</strong>. So each thread will have a cache for small objects without locks, which makes it very efficient to allocate small objects (&lt;=32k) under parallel programs.</p><p><em>Thread Cache (Each Thread gets this Thread Local Thread Cache)</em><br><img src="https://cdn-images-1.medium.com/max/2728/1*L6MpddL2RZY-kmguKL29jw.png" alt="Thread Cache (Each Thread gets this Thread Local Thread Cache)"></p><h3 id="page-heap"><a href="#page-heap" class="headerlink" title="page heap"></a>page heap</h3><p>The heap managed by TCMalloc consists of a collection of pages, <strong>where a set of consecutive pages can be represented by span</strong>. When allocated Object is larger than 32K, Pages Heap is used for allocation.</p><p><em>Page Heap (for span management)</em><br><img src="https://cdn-images-1.medium.com/max/3558/1*WBLW_v9sLqFMwNdn_DZ9AA.png" alt="Page Heap (for span management)"></p><p>When there is not enough memory to allocate small objects, go to page heap for memory. If there is not enough, page heap will ask more memory from the Operating System.</p><p>As such an allocation model maintains a user-spaced memory pool, it greatly improves the efficiency of memory allocation and release.</p><blockquote><p>Note: Even though go memory allocator was originally based on tcmalloc, but has diverged quite a bit.</p></blockquote><h2 id="Go-Memory-Allocator"><a href="#Go-Memory-Allocator" class="headerlink" title="Go Memory Allocator"></a>Go Memory Allocator</h2><p>We Know Go Runtime schedules <strong>Goroutines</strong> (<strong>G</strong>) onto <strong>Logical Processors </strong>(<strong>P</strong>) for execution. Likewise, TCMalloc Go also divides Memory Pages into a block of <strong>67 </strong>different classes Size.</p><blockquote><p>If you’re not familiar with the Go scheduler you can get an overview (<a href="https://povilasv.me/go-scheduler/" target="_blank" rel="noopener">Go scheduler: Ms, Ps &amp; Gs</a>), till then I will wait for you over here.</p></blockquote><p><em>Size Classes in Go</em><br><img src="https://cdn-images-1.medium.com/max/2000/1*dWZLGb3sJWncTdEFVuhxzw.png" alt="Size Classes in Go"></p><p>As Go manages pages at the granularity of <strong>8192B </strong>if this page is divided into a block size of <strong>1kB </strong>we get a total of 8 such blocks within that page for example.</p><p><img src="https://cdn-images-1.medium.com/max/2540/1*wF9KuVSk8o-16N64kB11UA.png" alt="8 KB page divided into a size class of 1KB (In Go pages are maintained at the granularity of 8KB)"><em>8 KB page divided into a size class of 1KB (In Go pages are maintained at the granularity of 8KB)</em></p><p>These run’s of pages in Go is also managed through a structure known as <strong>mspan</strong>.</p><p><em>The size classes and page count(run of pages gets chopped into objects of the given size) that gets allocated to each size classes are chosen so that rounding an allocation request up to the next size class wastes at most 12.5%</em></p><h3 id="mspan"><a href="#mspan" class="headerlink" title="mspan"></a>mspan</h3><p>Simply put, it ’s a double linked list object that contains the start address of the page, span class of the page that it has, and the number of pages it contains.</p><p><em>Illustrative Representation of a mspan in Go memory allocator</em><br><img src="https://cdn-images-1.medium.com/max/3086/1*EU3BwOrCI7KIFEninr-bxA.png" alt="Illustrative Representation of a mspan in Go memory allocator"></p><h3 id="mcache"><a href="#mcache" class="headerlink" title="mcache"></a>mcache</h3><p>Like TCMalloc Go provides each <strong>Logical Processors</strong>(<strong>P</strong>) a Local Thread Cache of Memory known as <strong>mcache</strong>, so that if Goroutine needs memory it can directly get it from the <strong>mcache</strong> without any <strong>locks </strong>being involved as at any point of time only one <strong>Goroutine </strong>will be running on <strong>Logical Processors</strong>(<strong>P</strong>).</p><p><strong>mcache </strong>contains a <strong>mspan</strong> of all class size as a cache.</p><p><em>Illustrative Representation of a Relationship between P, mcache, and mspan in Go.</em><br><img src="https://cdn-images-1.medium.com/max/3714/1*5eLTsavMYrixqr4H99FwmA.png" alt="Illustrative Representation of a Relationship between P, mcache, and mspan in Go."></p><blockquote><p>As there is mcache Per-P, so no need to hold locks when allocating from the mcache.</p></blockquote><p>For each class size, there are two types.</p><p><strong>1.</strong> <strong>scan</strong> — Object that contains a pointer.</p><p><strong>2.</strong> <strong>noscan</strong> — Object that doesn’t contains a pointer.</p><p>One benefits of this approach being while doing Garbage Collection, <strong>noscan </strong>object doesn’t need to be traversed to find any containing live object.</p><p><strong>What Goes to mcache ?.</strong></p><blockquote><p>Object size &lt;=32K byte are allocated directly to mcache using the corresponding size class mspan.</p></blockquote><p><strong>What happens When mcache has no free slot?</strong></p><p>A new mspan is obtained from the <strong>mcentral </strong>list of mspans of the required size class.</p><h3 id="mcentral"><a href="#mcentral" class="headerlink" title="mcentral"></a>mcentral</h3><p>mcentral Object collects all spans of a given size class and each mcentral is two lists of mspans.</p><p><strong>1.</strong> <strong>empty</strong> mspanList — List of mspans with no free objects or mspans that has is cached in an mcache.</p><p><strong>2.</strong> <strong>nonempty</strong> mspanList — List of spans with a free object.</p><p>When a new Span is requested from mcentral, it’s taken (if available) from the nonempty list of mspanList. The relationship between these two lists is as follow When a new span is requested, the request is fulfilled from the non-empty list and that span is put into the empty list. When the span is freed then based on the number of free objects in the span it is put back to the non-empty list.</p><p><em>Illustrative Representation of a mcentral</em><br><img src="https://cdn-images-1.medium.com/max/3762/1*_j2eG0lUdVQ8NRwgYy-DyA.png" alt="Illustrative Representation of a mcentral"></p><p>Each mcentral structure is maintained inside the <strong>mheap </strong>structure.</p><h3 id="mheap"><a href="#mheap" class="headerlink" title="mheap"></a>mheap</h3><blockquote><p>mheap is the Object that manages the heap in Go, only one global. It own the virtual addresses space.</p></blockquote><p><em>Illustrative Representation of a mheap.</em><br><img src="https://cdn-images-1.medium.com/max/2786/1*rTsieglF6GO1NW78KN8vkQ.png" alt="Illustrative Representation of a mheap."></p><p>As we can see from the above illustration <strong>mheap has an array of mcentral</strong>. This <strong>array contains mcentral of each span class</strong>.<br></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">central [numSpanClasses]<span class="keyword">struct</span> &#123;</span><br><span class="line">    mcentral mcentral</span><br><span class="line">    pad      [sys.CacheLineSize unsafe.Sizeof(mcentral&#123;&#125;)%sys.CacheLineSize]<span class="keyword">byte</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p></p><blockquote><p>Since We have mcentral for each span class, when a <strong>mspan </strong>is requested by <strong>mcache </strong>from mcentral, the <strong>lock </strong>is involved at individual <strong>mcentral</strong> level, so any other <strong>mcache</strong> requesting a <strong>mspan </strong>of different size at the same time can also be served.</p></blockquote><p><em>Padding makes sure that the MCentrals are</em> <em>spaced CacheLineSize bytes apart so that each MCentral.lock</em> <em>gets its own cache line </em>in order to avoid false sharing problems.</p><p>So what happens when this <strong>mcentral </strong>list is empty? <strong>mcentral </strong>obtains a run of pages from the <strong>mheap </strong>to use for spans of the required size class.</p><ul><li><p><strong>free[_MaxMHeapList]mSpanList</strong>: This is a spanList array. The <strong>mspan </strong>in each spanList consists of 1 ~ 127 (_MaxMHeapList — 1) pages. For example, free[3] is a linked list of <strong>mspans </strong>containing 3 pages. Free means free list, which is unallocated. Corresponding to the busy list.</p></li><li><p><strong>freelarge mSpanList</strong>: A list of <strong>mspans</strong>. The number of pages per element (that is, mspan) is greater than 127. It’s maintained as a mtreap Data structure. Corresponding to busylarge.</p><blockquote><p>Object of Size &gt; 32k, is a large object, allocated directly from mheap. These large request comes at an expenses of central lock, so only one P’s request can be served at any given point of time.</p></blockquote></li></ul><h2 id="Object-allocation-Flow"><a href="#Object-allocation-Flow" class="headerlink" title="Object allocation Flow"></a>Object allocation Flow</h2><p>• Size &gt; 32k is a large object, allocated directly from <strong>mheap.</strong></p><p>• Size &lt; 16B, using mcache’s tiny allocator allocation</p><p>• Size between 16B ~ 32k, calculate the sizeClass to be used and then use the block allocation of the corresponding sizeClass in mcache</p><p>• If the sizeClass corresponding to mcache has no available blocks, apply to mcentral.</p><p>• If there are no blocks available for mcentral, apply to mheap and <strong>use BestFit to find the most suitable mspan</strong>. If the application size is exceeded, it will be divided as needed to return the number of pages the user needs. The remaining pages constitute a new mspan, and the mheap free list is returned.</p><p>• If there is no span available for mheap, apply to the operating system for a new set of pages (at least 1MB).</p><blockquote><p>But Go allocates pages in even large size (called arena) at OS Level. Allocating a large run of pages amortizes the cost of talking to the operating system.</p></blockquote><p><strong>All memory requested on the heap comes from the arena. </strong>Let’s look at what this arena looks like.</p><h2 id="Go-Virtual-Memory"><a href="#Go-Virtual-Memory" class="headerlink" title="Go Virtual Memory"></a>Go Virtual Memory</h2><p>Lets us look into the memory of simple go program.<br></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p><em>process stats for a program</em><br><img src="https://cdn-images-1.medium.com/max/2000/1*4bePvN9LhkTkPWlRIWGgew.png" alt="process stats for a program"></p><p>So even for a simple go program virtual Space is around ~100 MB while RSS is just 696kB . Lets us try to figure out this difference first.</p><p><em>memory stats.</em><br><img src="https://cdn-images-1.medium.com/max/3458/1*JBeUo5u5l45-3qzEQrpJ3A.png" alt="map and smap stats."></p><p>So there are regions of memory which are sized around ~2MB, 64MB and 32MB. What are these?</p><h3 id="Arena"><a href="#Arena" class="headerlink" title="Arena"></a>Arena</h3><p>It turns out the virtual memory layout in go consists of a <strong>set</strong> of <strong>arenas. </strong>The initial heap mapping is one arena i.e 64MB(based on go 1.11.5).</p><p><em>current incremental arena size on a different system.</em><br><img src="https://cdn-images-1.medium.com/max/3148/1*yX9Q92T4B1aHEoQWTQI36g.png" alt="current incremental arena size on a different system."></p><p>So currently memory is mapped in small increments as our program needs it, and it starts with one arena (~64MB).</p><p><em>Please take these number with a grain of salt. Subject to change. </em>Earlier go used to reserve a continuous virtual address upfront, on a 64-bit system the arena size was 512 GB. (what happens if allocations are large enough and are <strong>rejected by mmap </strong>?)</p><p><strong>This set of arenas is what we call heap.</strong> In Go, each arena is managed at a granularity of 8192 B of pages.</p><p><em>Single arena ( 64 MB ).</em><br><img src="https://cdn-images-1.medium.com/max/3294/1*5pyhqsz3aVLyY_kRFc7Lig.png" alt="Single arena ( 64 MB )."></p><p>Go also has two more blocks which <strong>span </strong>and <strong>bitmap</strong>. <strong>Both of them are allocated off-heap and contains metadata of each arena. </strong>It’s mostly used during Garbage Collection (so we will leave it for now).</p><p>The classes of allocation strategy in Go we’ve just discussed, only scratch the surface in the fantastic diversity of memory allocation.</p><p>However, the general idea of the Go memory management is to allocate memory using different memory structures using different cache level memory for objects of different sizes. Splitting a single block of consecutive addresses received from the operating system, into a multi-level cache improve the efficiency of memory allocation by reducing the locks and then allocating memory allocations according to the specified size reduces memory fragmentation and facilitates faster GC after the memory is released.</p><p>I am leaving you with this Visual Overview of Go Memory Allocator for now.</p><p><em>Visual Overview of Runtime Memory Allocator.</em><br><img src="https://cdn-images-1.medium.com/max/3760/1*T9WO7O3EWTWJjCrxaOz4cg.png" alt="Visual Overview of Runtime Memory Allocator."></p><p><img src="https://cdn-images-1.medium.com/max/10000/1*-OQBs5b4u65NRQM8aFukAw.png" alt></p><p>Alright, that’s all for now. Thank you for reading so far.</p></div></article><p class="article-content share_center"><strong>Learned something? Share 👏 to help others find this article.</strong></p><div class="share share_center"><ul class="share__list"><li class="share__item"><a href="https://twitter.com/share?text=A visual guide to Go Memory Allocator from scratch (Golang)&amp;url=http://blog.ankuranand.com/2019/02/20/a-visual-guide-to-golang-memory-allocator-from-ground-up/index.html&amp;via=in_aanand" target="_blank"><svg class="icon share__icon share__icon--twitter"><use xlink:href="#icon-twitter" xmlns:xlink="https://www.w3.org/1999/xlink"/></svg> Tweet this</a></li></ul></div><div class="box-prev-next clearfix" style="margin-top:10px"><a class="show pull-left" href="/2018/11/29/a-closer-look-at-go-golang-type-system/"><i class="icon icon-angle-left"></i> </a><a class="show pull-right" href="/2019/03/14/communicating-sequential-processes-csp-for-go-developer-in-a-nutshell/"><i class="icon icon-angle-right"></i></a></div></div><a id="backTop" class="back-top"><i class="icon-angle-up"></i></a><div class="modal" id="modal"><span id="cover" class="cover hide"></span><div id="modal-dialog" class="modal-dialog hide-dialog"><div class="modal-header"><span id="close" class="btn-close">Close</span></div><hr><div class="modal-body"><ul class="list-toolbox"><li class="item-toolbox"><a class="CIRCLE" href="https://ankuranand.com" rel="noopener noreferrer" target="_self">About</a></li><li class="item-toolbox"><a class="CIRCLE" href="/atom.xml" rel="noopener noreferrer" target="_blank">RSS</a></li><li class="item-toolbox"><a class="CIRCLE" href="/search/" rel="noopener noreferrer" target="_self">Search</a></li></ul></div></div></div><div class="fexo-comments comments-post"><div id="gitalk-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script><script>const gitalk = new Gitalk({
  clientID: 'Infinity',
  clientSecret: '9ac2991775db990e81299dfa99a114395b58de3a',
  repo: 'blog',
  owner: 'ankur-anand',
  id: location.pathname.split('/')[4].substring(0, 45),
  // id: location.pathname,
  admin: ['ankur-anand'],
  labels: ['gicomment'],
  // facebook-like distraction free mode
  distractionFreeMode: false
})
gitalk.render('gitalk-container')</script></div><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css"><script type="text/javascript">function loadScript(e,t){var a=document.createElement("script");a.type="text/javascript",a.readyState?a.onreadystatechange=function(){"loaded"!=a.readyState&&"complete"!=a.readyState||(a.onreadystatechange=null,t())}:a.onload=function(){t()},a.src=e,document.getElementsByTagName("head")[0].appendChild(a)}window.onload=function(){loadScript("/js/bundle.js?235683",function(){})}</script><div class="svg-holder"><svg xmlns="https://www.w3.org/2000/svg"><symbol viewbox="0 0 32 32" id="icon-twitter"><title>twitter</title><path d="M31,6.696c-1.103,0.489-2.291,0.82-3.536,0.969c1.271-0.762,2.247-1.968,2.708-3.404c-1.189,0.705-2.508,1.218-3.909,1.493
          c-1.122-1.196-2.723-1.943-4.493-1.943c-3.398,0-6.154,2.755-6.154,6.154c0,0.483,0.055,0.953,0.159,1.402
          C10.66,11.111,6.125,8.66,3.089,4.937C2.561,5.846,2.256,6.902,2.256,8.031c0,2.135,1.086,4.019,2.737,5.123
          c-1.009-0.031-1.957-0.309-2.786-0.77c-0.002,0.025-0.002,0.052-0.002,0.078c0,2.982,2.122,5.469,4.937,6.034
          c-0.517,0.142-1.061,0.217-1.622,0.217c-0.396,0-0.782-0.039-1.158-0.112c0.784,2.444,3.057,4.225,5.75,4.274
          c-2.105,1.651-4.761,2.635-7.645,2.635c-0.496,0-0.985-0.029-1.467-0.086c2.723,1.746,5.958,2.765,9.434,2.765
          c11.321,0,17.512-9.379,17.512-17.512c0-0.268-0.005-0.533-0.018-0.796C29.131,9.014,30.174,7.93,31,6.696L31,6.696z"/></symbol></svg></div><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script></body>